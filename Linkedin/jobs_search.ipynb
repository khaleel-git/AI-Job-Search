{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinkedIn job search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LinkedIn Login, Sign in | LinkedIn'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.linkedin.com/login')\n",
    "driver.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = driver.find_element(By.ID, 'username')\n",
    "email.send_keys(os.environ['EMAIL'])\n",
    "\n",
    "password = driver.find_element(By.ID, 'password')\n",
    "password.send_keys(os.environ['PASSWORD'])\n",
    "\n",
    "password.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAKE SURE TO USE ONLY THIS URL TO AVOID BEING STUCK IN ERRORS\n",
    "\n",
    "url = \"https://www.linkedin.com/jobs/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/jobs/search/?keywords=Data+Engineer&location=Berlin%2C+Germany&geoId=103035651&f_TPR=r86400&f_WT=1%2C2%2C3&f_E=2%2C3%2C4&f_JT=F%2CC\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlencode\n",
    "params = {\n",
    "    'keywords': 'Data Engineer',\n",
    "    'location': 'Berlin, Germany',\n",
    "    'geoId': '103035651',\n",
    "    'f_TPR': 'r86400',  # Past 24 hours\n",
    "    'f_WT': '1,2,3',  # On-site=1, Remote=2, Hybrid=3\n",
    "    'f_E': '2,3,4',  # Entry level and Associate\n",
    "    'f_JT': 'F,C',  # Full-time\n",
    "}\n",
    "\n",
    "base_url = 'https://www.linkedin.com/jobs/search/'\n",
    "full_url = base_url + '?' + urlencode(params)\n",
    "\n",
    "print(full_url)\n",
    "driver.get(full_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Scraping Page 1\n",
      "============================================================\n",
      "Error during scrolling: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".jobs-search-results-list\"}\n",
      "  (Session info: chrome=142.0.7444.176); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "Symbols not available. Dumping unresolved backtrace:\n",
      "\t0x7ff7c758a235\n",
      "\t0x7ff7c72e2630\n",
      "\t0x7ff7c70716dd\n",
      "\t0x7ff7c70ca27e\n",
      "\t0x7ff7c70ca58c\n",
      "\t0x7ff7c711ed77\n",
      "\t0x7ff7c711baba\n",
      "\t0x7ff7c70bb0ed\n",
      "\t0x7ff7c70bbf63\n",
      "\t0x7ff7c75b5d60\n",
      "\t0x7ff7c75afe8a\n",
      "\t0x7ff7c75d1005\n",
      "\t0x7ff7c72fd71e\n",
      "\t0x7ff7c7304e1f\n",
      "\t0x7ff7c72eb7c4\n",
      "\t0x7ff7c72eb97f\n",
      "\t0x7ff7c72d18e8\n",
      "\t0x7ffb289be8d7\n",
      "\t0x7ffb2a0ec53c\n",
      "\n",
      "Found 11 jobs on current page\n",
      "  1. N/A at BWI GmbH\n",
      "  2. N/A at Canonical\n",
      "  3. N/A at ToysReloved\n",
      "  4. N/A at OBI Group Holding\n",
      "  5. N/A at kiresult\n",
      "  6. N/A at Strava\n",
      "  7. N/A at DKB | Deutsche Kreditbank AG\n",
      "  8. N/A at Aiven\n",
      "  9. N/A at SysEleven GmbH\n",
      "  10. N/A at netgo\n",
      "  11. N/A at Alignerr\n",
      "\n",
      "Total jobs scraped so far: 11\n",
      "Clicked next page button\n",
      "\n",
      "============================================================\n",
      "Scraping Page 2\n",
      "============================================================\n",
      "Error during scrolling: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".jobs-search-results-list\"}\n",
      "  (Session info: chrome=142.0.7444.176); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "Symbols not available. Dumping unresolved backtrace:\n",
      "\t0x7ff7c758a235\n",
      "\t0x7ff7c72e2630\n",
      "\t0x7ff7c70716dd\n",
      "\t0x7ff7c70ca27e\n",
      "\t0x7ff7c70ca58c\n",
      "\t0x7ff7c711ed77\n",
      "\t0x7ff7c711baba\n",
      "\t0x7ff7c70bb0ed\n",
      "\t0x7ff7c70bbf63\n",
      "\t0x7ff7c75b5d60\n",
      "\t0x7ff7c75afe8a\n",
      "\t0x7ff7c75d1005\n",
      "\t0x7ff7c72fd71e\n",
      "\t0x7ff7c7304e1f\n",
      "\t0x7ff7c72eb7c4\n",
      "\t0x7ff7c72eb97f\n",
      "\t0x7ff7c72d18e8\n",
      "\t0x7ffb289be8d7\n",
      "\t0x7ffb2a0ec53c\n",
      "\n",
      "Found 7 jobs on current page\n",
      "  1. N/A at Alignerr\n",
      "  2. N/A at Alignerr\n",
      "  3. N/A at adesso SE\n",
      "  4. N/A at Fujitsu\n",
      "  5. N/A at Delivery Hero\n",
      "  6. N/A at DIN Solutions GmbH\n",
      "  7. N/A at Deel\n",
      "\n",
      "Total jobs scraped so far: 18\n",
      "Next button not found - reached last page\n",
      "\n",
      "No more pages available\n",
      "\n",
      "============================================================\n",
      "SCRAPING COMPLETE\n",
      "============================================================\n",
      "Total jobs found: 18\n",
      "Data saved to linkedin_jobs.csv\n"
     ]
    }
   ],
   "source": [
    "def scroll_to_load_jobs(driver):\n",
    "    \"\"\"Scroll the job list to load all jobs on current page\"\"\"\n",
    "    try:\n",
    "        job_list = driver.find_element(By.CLASS_NAME, 'jobs-search-results-list')\n",
    "        \n",
    "        # Scroll within the job list container\n",
    "        last_height = driver.execute_script(\"return arguments[0].scrollHeight\", job_list)\n",
    "        \n",
    "        while True:\n",
    "            # Scroll down in the job list\n",
    "            driver.execute_script(\"arguments[0].scrollTo(0, arguments[0].scrollHeight);\", job_list)\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Calculate new scroll height\n",
    "            new_height = driver.execute_script(\"return arguments[0].scrollHeight\", job_list)\n",
    "            \n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "            \n",
    "        print(\"Finished loading all jobs on current page\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during scrolling: {e}\")\n",
    "\n",
    "def extract_job_data(job_card):\n",
    "    \"\"\"Extract data from a single job card\"\"\"\n",
    "    try:\n",
    "        data = {}\n",
    "        \n",
    "        # Job title\n",
    "        try:\n",
    "            title_elem = job_card.find_element(By.CSS_SELECTOR, '.job-card-list__title strong')\n",
    "            data['title'] = title_elem.text.strip()\n",
    "        except:\n",
    "            data['title'] = 'N/A'\n",
    "        \n",
    "        # Company name\n",
    "        try:\n",
    "            company_elem = job_card.find_element(By.CSS_SELECTOR, '.artdeco-entity-lockup__subtitle')\n",
    "            data['company'] = company_elem.text.strip()\n",
    "        except:\n",
    "            data['company'] = 'N/A'\n",
    "        \n",
    "        # Location\n",
    "        try:\n",
    "            location_elem = job_card.find_element(By.CSS_SELECTOR, '.artdeco-entity-lockup__caption li')\n",
    "            data['location'] = location_elem.text.strip()\n",
    "        except:\n",
    "            data['location'] = 'N/A'\n",
    "        \n",
    "        # Job link\n",
    "        try:\n",
    "            link_elem = job_card.find_element(By.CSS_SELECTOR, 'a.job-card-container__link')\n",
    "            data['link'] = link_elem.get_attribute('href')\n",
    "        except:\n",
    "            data['link'] = 'N/A'\n",
    "        \n",
    "        # Job ID (from link)\n",
    "        try:\n",
    "            if 'link' in data and data['link'] != 'N/A':\n",
    "                job_id = data['link'].split('/jobs/view/')[1].split('/')[0].split('?')[0]\n",
    "                data['job_id'] = job_id\n",
    "            else:\n",
    "                data['job_id'] = 'N/A'\n",
    "        except:\n",
    "            data['job_id'] = 'N/A'\n",
    "        \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting job data: {e}\")\n",
    "        return None\n",
    "\n",
    "def scrape_current_page(driver):\n",
    "    \"\"\"Scrape all jobs from the current page\"\"\"\n",
    "    jobs_data = []\n",
    "    \n",
    "    try:\n",
    "        # Wait for job cards to load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, 'job-card-container'))\n",
    "        )\n",
    "        \n",
    "        # Get all job cards\n",
    "        job_cards = driver.find_elements(By.CLASS_NAME, 'job-card-container')\n",
    "        print(f\"Found {len(job_cards)} jobs on current page\")\n",
    "        \n",
    "        for idx, job_card in enumerate(job_cards, 1):\n",
    "            job_data = extract_job_data(job_card)\n",
    "            if job_data:\n",
    "                jobs_data.append(job_data)\n",
    "                print(f\"  {idx}. {job_data['title']} at {job_data['company']}\")\n",
    "        \n",
    "        return jobs_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping current page: {e}\")\n",
    "        return jobs_data\n",
    "\n",
    "def click_next_page(driver):\n",
    "    \"\"\"Click the next page button if available\"\"\"\n",
    "    try:\n",
    "        # Try to find the next button\n",
    "        next_button = driver.find_element(By.CSS_SELECTOR, 'button[aria-label=\"View next page\"]')\n",
    "        \n",
    "        # Check if button is disabled\n",
    "        if 'disabled' in next_button.get_attribute('class'):\n",
    "            print(\"Next button is disabled - no more pages\")\n",
    "            return False\n",
    "        \n",
    "        # Scroll to the button\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Click the button\n",
    "        next_button.click()\n",
    "        print(\"Clicked next page button\")\n",
    "        \n",
    "        # Wait for new page to load\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Wait for job cards to appear\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, 'job-card-container'))\n",
    "        )\n",
    "        \n",
    "        return True\n",
    "    except NoSuchElementException:\n",
    "        print(\"Next button not found - reached last page\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error clicking next page: {e}\")\n",
    "        return False\n",
    "\n",
    "def scrape_all_pages(driver, max_pages=5):\n",
    "    \"\"\"Scrape jobs from all pages with pagination\"\"\"\n",
    "    all_jobs = []\n",
    "    page = 1\n",
    "    \n",
    "    while page <= max_pages:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Scraping Page {page}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Scroll to load all jobs on current page\n",
    "        scroll_to_load_jobs(driver)\n",
    "        \n",
    "        # Scrape current page\n",
    "        jobs = scrape_current_page(driver)\n",
    "        all_jobs.extend(jobs)\n",
    "        \n",
    "        print(f\"\\nTotal jobs scraped so far: {len(all_jobs)}\")\n",
    "        \n",
    "        # Try to go to next page\n",
    "        if not click_next_page(driver):\n",
    "            print(\"\\nNo more pages available\")\n",
    "            break\n",
    "        \n",
    "        page += 1\n",
    "    \n",
    "    return all_jobs\n",
    "\n",
    "# Scrape all pages (max 5 pages)\n",
    "all_jobs = scrape_all_pages(driver, max_pages=5)\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"SCRAPING COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total jobs found: {len(all_jobs)}\")\n",
    "\n",
    "# Optional: Save to CSV\n",
    "import csv\n",
    "with open('linkedin_jobs.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    if all_jobs:\n",
    "        writer = csv.DictWriter(f, fieldnames=all_jobs[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_jobs)\n",
    "        print(f\"Data saved to linkedin_jobs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
